\chapter{Differential Geometry}
\label{cha:differentialgeometry}

\section{Introduction}

\section{Topology}

The topology of a space specifies the connectedness, continuity, compactness,
and other properties that can be defined on the space of specified
dimension. It brings in the concept of open neighbourhoods of points. Types of
topology include

\begin{enumerate}
\item Discrete (OD) topology, $\dntopology{}$.
\item Real topology, $\rntopology{n}$.
\item Spherical topology, $\sntopology{n}$.
\end{enumerate}

\section{Manifold}

A manifold $\manifold{M}$ is a topological space (\ie a set of points with a specified
topology) of a fixed dimension $n$ in which every point is homeomorphic to
$\rntopology{n}$ \ie they admit a coordinate system that is locally
Euclidean. For \FieldML purposes we need to relax this last restriction because
we wish to allow branching structures, but we will still refer to this as a
manifold â€“ the neighbourhoods of points at the branch do not admit a
coordinate system that is locally Euclidean.

\section{Vectors and Covectors}

To motivate this section consider standing on a hill. Now, consider two
vectors that can be applied. If we move around the hill at constant height we
can talk about our velocity vector around the hill. We can also talk about
moving down the slope of the hill. The gradient vector would give the steepest
direction down the hill. If both these vectors had a unit magnitude in what
ever units of measurement we are using we might consider these vectors to be
similar (apart from the obvious difference in direction). Now consider a
change of units \eg from $\m$ to $\cm$. If our velocity was prevoiusly
$\nunit{1}{\mps}$ then it would be now $\nunit{100}{\cmps}$. However, our
gradient vector that was previously $\nunit{1}{\pmetre}$ would become
$\nunit{0.01}{\pcm}$. If these two ``vectors'' are really so similar why do
the transform differently under a change of units/coordinates? The reason is
that these two ``vectors'' are not actually that similar at all. Indeed, one
of them is not a vector at all but rather it is a \emph{covector}.

\section{Differential geometry of manifolds}

\subsection{Connections}


\subsection{Covariant Differentiation}

A covariant derivative is a derivative along a tangent vector of a
manifold. It is a generalisation of a directional derivative to manifolds. It
is a derivative that under a coordinate transforms covariantly \ie linearly
with the Jacobian. A covariant derivative is equivalent to the idea of a
connection. For a connection $\connection{}{}$ and a vector field $X$ then
$\covarderivop{X}{}$ is the covariant derivative. 

The covariant derivative of a $\pbrac{r,s}$ tensor is an $\pbrac{r,s+1}$
tensor defined by
\begin{equation}
  \covarderivop{X}{Y}=\covarderivop{X}{\pbrac{X^{i}e_{i}}}=Y\pbrac{X^{i}}e_{i}+X^{i}\covarderivop{Y}{e_{i}}
\end{equation}

The covariant derivative has the following properties
%\begin{list}
%\item Sumation Rule: $abc$ \\
%\item kaldf
%\end{list}

\subsubsection{Double covariant differentiation}

For an $\pbrac{r,s}$ tensor field, $T$, the double covariant derivative is
\begin{equation}
  \doublecovarderivop{}{T}=\covarderivop{}{\covarderivop{}{T}}
\end{equation}
which is an $\pbrac{r,s+2}$ tensor field. It is defined by
\begin{equation}
  \doublecovarderivop{X,Y}{T}=\covarderivop{X}{\covarderivop{Y}{T}}-\covarderivop{\connection{X}{Y}}{T}
\end{equation}

\section{Tensor Analysis}
\subsection{Base vectors}

Now, if we have a vector, $\vectr{v}$ we can write
\begin{equation}
  \vectr{v}=v^{i}\vectr{g}_{i}
\end{equation}
where $v^{i}$ are the components of the contravariant vector, and
$\vectr{g}_{i}$ are the covariant base vectors.

Similarly, the vector $\vectr{v}$ can also be written as 
\begin{equation}
  \vectr{v}=v_{i}\vectr{g}^{i}
\end{equation}
where $v_{i}$ are the components of the covariant vector, and
$\vectr{g}^{i}$ are the contravariant base vectors. 

We now note that
\begin{equation}
  \vectr{v}=v^{i}\vectr{g}_{i}=v^{i}\sqrt{g_{ii}}\hat{\vectr{g}_{i}}
\end{equation}
where $v^{i}\sqrt{g_{ii}}$ are the physical components of the vector and
$\hat{\vectr{g}_{i}}$ are the unit vectors given by
\begin{equation}
  \hat{\vectr{g}_{i}}=\dfrac{\vectr{g}_{i}}{\sqrt{g_{ii}}}
\end{equation}

\subsection{Metric Tensors}
\label{sec:metric tensors}

Metric tensors are the inner product of base vectors. If $\vectr{g}_{i}$ are the
covariant base vectors then the covariant metric tensor is given by
\begin{equation}
  g_{ij}=\dotprod{\vectr{g}_{i}}{\vectr{g}_{j}}
\end{equation}

Similarily if $\vectr{g}^{i}$ are the contravariant base vectors then the
contravariant metric tensor is given by 
\begin{equation}
  g^{ij}=\dotprod{\vectr{g}^{i}}{\vectr{g}^{j}}
\end{equation}

We can also form a mixed metric tensor from the dot product of a contravariant
and a covariant base vector \ie
\begin{equation}
  g^{i}_{.j}=\dotprod{\vectr{g}^{i}}{\vectr{g}_{j}}
\end{equation}
and 
\begin{equation}
  g_{i}^{.j}=\dotprod{\vectr{g}_{i}}{\vectr{g}^{j}}
\end{equation}

Note that for mixed tensors the ``.'' indicates the order of the index \ie
$g^{i}_{.j}$ indicates that the first index is contravariant and the second
index is covariant whereas $g_{i}^{.j}$ indicates that the first index is
covariant and the second index is contravariant.

If the base vectors are all mutually orthogonal and constant then
$\vectr{g}_{i}=\vectr{g}^{i}$ and $g_{ij}=g^{ij}$.

The metric tensors generalise (Euclidean) distance \ie
\begin{equation}
  ds^{2}=g_{ij}dx^{i}dx^{j}
\end{equation}

\subsubsection{Raising and lowering indices}

Note that multiplying by the covariant metric tensor lowers indices \ie
\begin{equation}
  \begin{split}
    \vectr{A}_{i} &= g_{ij}\vectr{A}^{j} \\
    A_{ij} &= g_{ik}g_{jl}A^{kl} = g_{jk}A_{i}^{.k} = g_{ik}A^{k}_{.j} 
  \end{split}
\end{equation}
and that multiplying by the contravariant metric tensor raises indices \ie
\begin{equation}
  \begin{split}
  \vectr{A}^{i} &=  g^{ij}\vectr{A}_{j} \\
   A^{ij} &= g^{ik}g^{jl}A_{kl} = g^{ik}A_{k}^{.j} = g^{jk}A^{i}_{.k}
  \end{split}
\end{equation}
and for the mixed tensors
\begin{equation}
  \begin{split}
  A_{i}^{.j} &= g^{jk}A_{ik} = g_{ik}A^{kj} \\
  A^{i}_{.j} &= g^{ik}A_{kj} = g_{jk}A^{ik} \\
  \end{split}
\end{equation}

We can denote a tensor in which all indicies have been raised as a
\emph{sharp} tensor, $\sharptensor{\tensor{A}}$, and one in which all indicies have been lowered as a
\emph{flat} tensor, $\flattensor{\tensor{A}}$. This is known as \emph{musical isomorphism} \ie
isomorphism between the tangent and cotangent bundles of a manifold, $\manifold{M}$.
\begin{equation}
  \mapping{\sharptensor{}}{\cotangentbundle{M}}{\tangentbundle{M}}
\end{equation}
and
\begin{equation}
  \mapping{\flattensor{}}{\tangentbundle{M}}{\cotangentbundle{M}}
\end{equation}

\subsubsection{Induced metric}

An induced metric is the metric tensor induced on a submanifold that has been
embedded into a larger manifold with a metric. If $\vectr{\xi}$ are the
coordinates in the submanifold and $\fnof{\vectr{x}}{\vectr{\xi}}$ are the
functions which embedded the submanifold into a larger manifold then the
induced metric is given by
\begin{equation}
  g_{ab}=\delby{x^{\mu}}{\xi^{a}}\delby{x^{\nu}}{\xi^{b}}g_{\mu\nu}
\end{equation}
where $a, b$ are the coordinate indices in the submanifold, $\mu, \nu$ are the
coordinate indices in the larger manifold, $g_{\mu\nu}$ are the components of
the metric tensor in the larger manifold and $g_{ab}$ are the components of
the induced metric in the submanifold.

\subsection{Transformations}

The transformation rules for tensors in going from a $\vectr{\nu}$ coordinate
system to a $\vectr{\xi}$ coordinate system are as follows: 


For a covariant vector (a rank (0,1) tensor)
\begin{equation}
  {\tilde{a}}_{i}=\delby{\nu^{a}}{\xi^{i}}a_{a}
\end{equation}

For a contravariant vector (a rank (1,0) tensor)
\begin{equation}
  {\tilde{a}}^{i}=\delby{\xi^{i}}{\nu^{a}}a^{a}
\end{equation}

For a covariant tensor (a rank (0,2) tensor)
\begin{equation}
  {\tilde{A}}_{ij}=\delby{\nu^{a}}{\xi^{i}}\delby{\nu^{b}}{\xi^{j}}A_{ab} 
\end{equation}

For a contravariant tensor (a rank (2,0) tensor)
\begin{equation}
  {\tilde{A}}^{ij}=\delby{\xi^{i}}{\nu^{a}}\delby{\xi^{j}}{\nu^{b}}A^{ab}
\end{equation}

and for Mixed tensors (rank (1,1) tensors)
\begin{equation}
  {\tilde{A}}^{i}_{.j}=\delby{\xi^{i}}{\nu^{a}}\delby{\nu^{b}}{\xi^{j}}A^{a}_{.b}
\end{equation}
and
\begin{equation}
  {\tilde{A}}_{i}^{.j}=\delby{\nu^{a}}{\xi^{i}}\delby{\xi^{j}}{\nu^{b}}A_{a}^{.b}
\end{equation}

\subsection{Derivatives}
\label{subsec:function derivatives}

\subsubsection{Scalars}

We note that a scalar quantity $\fnof{u}{\vectr{\xi}}$ has derivatives
\begin{equation}
  \delby{u}{\xi^{i}}=\partialderiv{u}{i}
\end{equation}

Or more formally, the covariant derivative ($\covarderiv{\cdot}{\cdot}$) of a
rank 0 tensor $u$ is
\begin{equation}
  \covarderiv{u}{i}=\delby{u}{\xi^{i}}=\partialderiv{u}{i}
\end{equation}

In more formal mathematical notation consider $f$ as a map between the
manifolds $\manifold{M}$ and $\manifold{N}$ \ie
\begin{equation}
  \mapping{f}{\manifold{M}}{\manifold{N}}
\end{equation}
then, at the point $u$, the derivative can be thought of as 
\begin{equation}
  \mapping{\derivativeop{u}{f}}{\tangentspace{M}{u}}{\tangentspace{N}{\fnof{f}{u}}}
\end{equation}
\ie the derivative operator takes a vector $v\in\tangentspace{M}{u}$ and maps
it to another vector $w\in\tangentspace{N}{\fnof{f}{u}}$.

Second derivatives. The second derivative or Hessian operator is defined as
\begin{equation}
  \mapping{\hessianop{u,v}{f}}{\tangentspace{\tangentspace{M}{u}}{v}}{\tangentspace{\tangentspace{N}{\fnof{f}{u}}}{\fnof{f^{'}}{v}}}
\end{equation}
\ie the hessian operator takes the first input as a vector
$v\in\tangentspace{M}{u}$ as the base direction you are moving in and a
second input as a vector $w\in\tangentspace{\tangentspace{M}}{}{v}$ as the direction
you are varying in.

The definition of the covariant Hessian is
\begin{equation}
  \hessianop{X,Y}{f} = \funccomposition{X}{\funccomposition{Y}{f}}-\funccomposition{\connection{X}{Y}}{f}
\end{equation}
or in component notation
\begin{equation}
  \hessianop{}{f}=\pbrac{\deltwoby{f}{x^{i}}{x^{j}}-\christoffel{k}{i}{j}\delby{f}{x^{k}}}\tensorprod{dx^{i}}{dx^{j}}
\end{equation}



\subsubsection{Vectors}

The derivatives of a vector $\vectr{v}$ are given by
\begin{equation}
  \begin{split}
    \delby{\vectr{v}}{\xi^{i}} &=
    \delby{}{\xi^{i}}\pbrac{v^{k}\vectr{g}_{k}} \\
    &= \delby{v^{k}}{\xi^{i}}\vectr{g}_{k}+v^{k}\delby{\vectr{g}_{k}}{\xi^{i}} \\
    &= \partialderiv{v^{k}}{i}\vectr{g}_{k}+v^{k}\partialderiv{\vectr{g}_{k}}{i}
  \end{split}
\end{equation}

Now introducing the notation
\begin{equation}
  \christoffelsecond{i}{j}{k} = \dotprod{\vectr{g}^{i}}{\delby{\vectr{g}_{j}}{x^{k}}}
\end{equation}
where $\christoffelsecond{i}{j}{k}$ are the Christoffel symbols of the second
kind. 

Note that the Christoffel symbols of the first kind are given by
\begin{equation}
  \christoffelfirst{i}{j}{k} = \dotprod{\vectr{g}_{i}}{\delby{\vectr{g}_{j}}{x^{k}}}
\end{equation}

Note that
\begin{equation}
  \begin{split}
    \christoffel{i}{j}{k} &= \dotprod{\vectr{g}^{i}}{\partialderiv{\vectr{g}_{j}}{k}} \\
    &=\dotprod{\vectr{g}^{i}}{\christoffelsecond{l}{j}{k}\vectr{g}_{l}} \\
    &= \christoffel{i}{j}{l}g^{i}_{.l} 
  \end{split}
\end{equation}

The Christoffel symbols of the first kind are also given by
\begin{equation}
  \christoffelfirst{i}{j}{k}=\frac{1}{2}\pbrac{\delby{g_{ij}}{\xi^{k}}+\delby{g_{ik}}{\xi^{j}}-\delby{g_{jk}}{\xi^{i}}}
\end{equation}
and that Christoffel symbols of the second kind are given by
\begin{equation}
  \begin{split}
    \christoffelsecond{i}{j}{k} &= g^{il}\christoffelfirst{l}{j}{k} \\
    &= \frac{1}{2}g^{il}\pbrac{\delby{g_{lj}}{\xi^{k}}+\delby{g_{lk}}{\xi^{j}}-\delby{g_{jk}}{\xi^{l}}} 
  \end{split}
\end{equation}

Note that Christoffel symbols are not tensors and the have the following
transformation laws from $\vectr{\nu}$ to $\vectr{\xi}$ coordinates
\begin{align}
  \christoffelfirst{i}{j}{k} &=
  \christoffelfirst{a}{b}{c}\delby{\nu^{b}}{\xi^{j}}\delby{\nu^{c}}{\xi^{k}}\delby{\nu^{a}}{\xi^{i}}+
  g_{ab}\delby{\nu^{c}}{\xi^{i}}\deltwoby{\nu^{c}}{\xi^{j}}{\xi^{k}} \\
  \christoffelsecond{i}{j}{k} &= \christoffelsecond{a}{b}{c}\delby{\xi^{i}}{\nu^{a}}\delby{\nu^{b}}{\xi^{k}}\delby{\nu^{c}}{\xi^{j}}+
  \delby{\xi^{i}}{\nu^{a}}\deltwoby{\nu^{a}}{\xi^{j}}{\xi^{k}} \\
\end{align}

We can now write (BELOW SEEMS WRONG - CHECK)
\begin{equation}
  \begin{split}
    \partialderiv{\vectr{v}}{i}&=\partialderiv{v^{k}}{i}\vectr{g}_{k}+\christoffel{k}{i}{j}v^{j}\vectr{g}_{j}\\
    &=\partialderiv{v^{k}}{i}\vectr{g}_{k}+\christoffel{j}{i}{k}v^{k}\vectr{g}_{k}\\
    &=\pbrac{\partialderiv{v^{k}}{i}+\christoffel{j}{i}{k}v^{k}}\vectr{g}_{k}\\
    &=\covarderiv{v^{k}}{i}\vectr{g}_{k}
  \end{split}
\end{equation}
where $\covarderiv{v^{k}}{i}$ is the covariant derivative of $v^{k}$ . 

The covariant derivative of a contravariant (rank (0,1)) tensor $v^{k}$ is
\begin{equation}
  \covarderiv{v^{k}}{i} =\partialderiv{v^{k}}{i}+\christoffel{k}{i}{j}v^{j}
\end{equation}
and the covariant derivative of a covariant tensor  (rank (1,0)) $v_{k}$ is
\begin{equation}
  \covarderiv{v_{k}}{i} =\partialderiv{v_{k}}{i}-\christoffel{j}{k}{i}v_{j}
\end{equation}

\subsubsection{Tensors}

The covariant derivative of a contravariant (rank (0,2)) tensor $W^{mn}$ is
\begin{equation}
  \covarderiv{W^{mn}}{i}=\partialderiv{W^{mn}}{i}+\christoffel{m}{j}{i}W^{jn}+\christoffel{n}{j}{i}W^{mj}
\end{equation}
and the covariant derivative of a covariant (rank (2,0)) tensor $W_{mn}$ is
\begin{equation}
  \covarderiv{W_{mn}}{i}=\partialderiv{W_{mn}}{i}-\christoffel{j}{m}{i}W_{jn}-\christoffel{j}{n}{i}W_{mj}
\end{equation}
and the covariant derivative of a mixed (rank (1,1)) tensor $W^{m}_{.n}$ is
\begin{equation}
  \covarderiv{W^{m}_{.n}}{i}=\partialderiv{W^{m}_{.n}}{i}+\christoffel{m}{j}{i}W^{j}_{.n}-\christoffel{j}{n}{i}W^{m}_{.j}
\end{equation}

\subsection{Common Operators}

For tensor equations to hold in any coordinate system the equations must
involve tensor quantities \ie covariant derivatives rather than partial derivatives.

\subsubsection{Gradient}

As the covariant derivative of a scalar is just the partial derivative the
gradient of a scalar function $\phi$ using covariant derivatives is
\begin{equation}
  \gradop \phi = \gradient{}{\phi}=\covarderiv{\phi}{i}\vectr{g}^{i}=\partialderiv{\phi}{i}\vectr{g}^{i}
\end{equation}
and
\begin{equation}
  \gradient{}{\phi}=\partialderiv{\phi}{i}\vectr{g}^{i}=\partialderiv{\phi}{i}g^{ij}\vectr{g}_{j}
\end{equation}

\subsubsection{Divergence}

The divergence of a vector using covariant derivatives is
\begin{equation}
  \divop \vectr{\phi} = \divergence{}{\vectr{\phi}}=\covarderiv{\phi^{i}}{i}=\frac{1}{\sqrt{\abs{g}}}\partialderiv{\pbrac{\sqrt{\abs{g}}\phi^{i}}}{i}
\end{equation}
where $g$ is the determinant of the covariant metric tensor $g_{ij}$.

\subsubsection{Curl}

The curl of a vector using covariant derivatives is
\begin{equation}
  \curlop \vectr{\phi} = \curl{}{\vectr{\phi}}=\frac{1}{\sqrt{g}}\pbrac{\covarderiv{\phi_{j}}{i}-\covarderiv{\phi_{i}}{j}}\vectr{g}_{k}
\end{equation}
where $g$ is the determinant of the covariant metric tensor $g_{ij}$.

\subsubsection{Laplacian}

The Laplacian of a scalar using covariant derivatives is
\begin{equation}
  \laplacian{}{\phi}=\divop\pbrac{\gradop\phi}=\divergence{}{\gradient{}{\phi}}=\mixedderiv{\phi}{i}{i}=\frac{1}{\sqrt{g}}\partialderiv{\pbrac{\sqrt{g}g^{ij}\partialderiv{\phi}{j}}}{i}
\end{equation}
where $g$ is the determinant of the covariant metric tensor $g_{ij}$.

The Laplacian of a vector using covariant derivatives is
\begin{equation}
  \laplacian{}{\vectr{\phi}}=\gradop\pbrac{\divop\vectr{\phi}}-\curlop \pbrac{\curlop\vectr{\phi}}==\mixedderiv{\vectr{\phi}}{i}{i}
\end{equation}

The Laplacian of a contravariant (rank (0,1)) tensor $\phi^{k}$ is
\begin{equation}
  \laplacian{}{\vectr{\phi}}=\pbrac{\laplacian{}{\phi_{k}}-2g^{ij}\christoffel{K}{j}{H}\delby{\phi^{h}}{x^{i}}+\phi^{h}\delby{g^{ij}\christoffel{K}{i}{j}}{x^{h}}}\vectr{e}^{k}
\end{equation}
and the covariant derivative of a covariant tensor  (rank (1,0)) $\phi_{k}$ is
\begin{equation}
  \laplacian{}{\vectr{\phi}}=\pbrac{\laplacian{}{\phi_{k}}-2g^{ij}\christoffel{h}{j}{k}\delby{\phi_{h}}{x^{i}}+\phi_{h}g^{ij}\delby{\christoffel{h}{i}{j}}{x^{i}}}\vectr{e}_{k}
\end{equation}

\section{Curves}

\epstexfigure{DifferentialGeometry/svgs/curve.eps_tex}{A curve in space.}{A
  parametised curve in space. The position, $\fnof{\vectr{r}}{\xi}$ is given in
  terms of the curve parameter $\xi$. $\vectr{t}$ is the tangent vector to the
  curve and $\vectr{n}$ is the normal vector to the curve.}{fig:curve}{1.0}
